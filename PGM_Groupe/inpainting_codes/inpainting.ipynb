{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19294,"status":"ok","timestamp":1734470265116,"user":{"displayName":"samar rabeh","userId":"13396335607551022904"},"user_tz":-60},"id":"U1Bv2xG_K-fq","outputId":"a0cc20fc-a9f6-4dc8-ee2c-2be42c43a325"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1734470265116,"user":{"displayName":"samar rabeh","userId":"13396335607551022904"},"user_tz":-60},"id":"vmZh8dhQL_Nb","outputId":"039120e5-65fb-40bf-c362-b3ad2d0c653e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Chemins de recherche actuels : ['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/usr/local/lib/python3.10/dist-packages/setuptools/_vendor', '/root/.ipython', '/content/drive/My Drive/work/notebooks']\n"]}],"source":["import sys\n","import os\n","# Chemin vers votre dossier de travail\n","work_dir = '/content/drive/My Drive/work/notebooks'\n","# Ajouter le dossier au path pour permettre les imports\n","sys.path.append(work_dir)\n","# Vérifiez que le chemin est bien ajouté\n","print(\"Chemins de recherche actuels :\", sys.path)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14149,"status":"ok","timestamp":1734470279252,"user":{"displayName":"samar rabeh","userId":"13396335607551022904"},"user_tz":-60},"id":"G-kk3jQmKmh8"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from models import NoiseConditionalScoreNetwork\n","import torch\n","import os\n","from load_data import load_dataset\n","import gc\n","from tqdm import tqdm\n","from torchvision.utils import save_image, make_grid\n","from PIL import Image\n","from my_utils import distribution2score\n","import numpy as np\n","from typing import Tuple\n","import torchvision"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1734470279253,"user":{"displayName":"samar rabeh","userId":"13396335607551022904"},"user_tz":-60},"id":"vzHSnpvqKmh_"},"outputs":[],"source":["def anneal_Langevin_dynamics_inpainting(\n","    noisy_image,  # renamed x_mod\n","    clean_image,  # renamed image\n","    score_model,  # renamed scorenet\n","    noise_levels,  # renamed sigmas\n","    resolution,  # renamed img_size\n","    channels,  # renamed n_channels\n","    fill_direction=\"left\",  # renamed direction\n","    steps_per_level=100,  # renamed n_steps_each\n","    learning_rate=0.000008,  # renamed step_lr\n","):\n","    def apply_mask_and_extract_region(img, direction, size, value=1.0):\n","        \"\"\"Create mask and extract region based on the specified direction.\"\"\"\n","        region_mask = torch.zeros_like(img)\n","        if direction == \"left\":\n","            region_mask[:, :, :, : size // 2] = value\n","            return img[:, :, :, : size // 2], region_mask\n","        elif direction == \"right\":\n","            region_mask[:, :, :, size // 2 :] = value\n","            return img[:, :, :, size // 2 :], region_mask\n","        elif direction == \"top\":\n","            region_mask[:, :, : size // 2, :] = value\n","            return img[:, :, : size // 2, :], region_mask\n","        elif direction == \"bottom\":\n","            region_mask[:, :, size // 2 :, :] = value\n","            return img[:, :, size // 2 :, :], region_mask\n","        raise ValueError(\"Invalid direction specified\")\n","\n","    generated_images = []\n","    noisy_image = noisy_image.view(-1, channels, resolution, resolution)\n","    expanded_clean_image = clean_image.unsqueeze(1).expand(-1, noisy_image.shape[1], -1, -1, -1)\n","    expanded_clean_image = expanded_clean_image.contiguous().view(-1, channels, resolution, resolution)\n","\n","    # Apply mask and extract half image\n","    target_region, region_mask = apply_mask_and_extract_region(expanded_clean_image, fill_direction, resolution)\n","    occluded_image = clean_image * region_mask\n","\n","    with torch.no_grad():\n","        for idx, noise_level in tqdm(enumerate(noise_levels), total=len(noise_levels), desc=\"Langevin dynamics sampling\"):\n","            labels = torch.full((noisy_image.shape[0],), idx, dtype=torch.long, device=noisy_image.device)\n","            step_size = learning_rate * (noise_level / noise_levels[-1]) ** 2\n","\n","            # Add noise to the target region\n","            corrupted_region = target_region + torch.randn_like(target_region) * noise_level\n","            noisy_image[region_mask > 0] = corrupted_region[region_mask > 0]  # Update only masked region\n","\n","            for _ in range(steps_per_level):\n","                generated_images.append(torch.clamp(noisy_image, 0.0, 1.0).to(\"cpu\"))\n","                random_noise = torch.randn_like(noisy_image) * np.sqrt(step_size * 2)\n","                gradient = score_model(noisy_image, labels)\n","                noisy_image += step_size * gradient + random_noise\n","                noisy_image[region_mask > 0] = corrupted_region[region_mask > 0]  # Reapply the corrupted region\n","\n","    return generated_images, occluded_image\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1734470279253,"user":{"displayName":"samar rabeh","userId":"13396335607551022904"},"user_tz":-60},"id":"G62Ug4FDKmiA"},"outputs":[],"source":["import numpy as np\n","import torchvision\n","from typing import Tuple\n","\n","def load_CIFAR10() -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"Load CIFAR-10 dataset.\"\"\"\n","    cifar10_url = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n","    torchvision.datasets.CIFAR10.url = cifar10_url\n","\n","    train_dataset = torchvision.datasets.CIFAR10(root=\"./\", train=True, download=True)\n","    test_dataset = torchvision.datasets.CIFAR10(root=\"./\", train=False, download=True)\n","\n","    return train_dataset.data, test_dataset.data\n","\n","def load_MNIST() -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"Load MNIST dataset.\"\"\"\n","    train_dataset = torchvision.datasets.MNIST(root=\"./\", train=True, download=True)\n","    test_dataset = torchvision.datasets.MNIST(root=\"./\", train=False, download=True)\n","\n","    # Convert data to numpy and add a channel dimension\n","    train_data = np.expand_dims(train_dataset.data.numpy(), axis=-1)\n","    test_data = np.expand_dims(test_dataset.data.numpy(), axis=-1)\n","\n","    return train_data, test_data\n","\n","def load_CELEBA() -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"Load CelebA dataset.\"\"\"\n","    celeba_url = \"https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\"\n","    torchvision.datasets.CelebA.url = celeba_url\n","\n","    train_dataset = torchvision.datasets.CelebA(root=\"./\", split=\"train\", download=True)\n","    test_dataset = torchvision.datasets.CelebA(root=\"./\", split=\"test\", download=True)\n","\n","    # Extract data (ensure compatibility with numpy arrays)\n","    train_data = np.array(train_dataset.data)\n","    test_data = np.array(test_dataset.data)\n","\n","    return train_data, test_data\n","\n","def _load_dataset(name: str) -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"Load a specific dataset based on its name.\"\"\"\n","    loaders = {\n","        \"mnist\": load_MNIST,\n","        \"cifar10\": load_CIFAR10,\n","        \"celeba\": load_CELEBA,\n","    }\n","\n","    if name.lower() not in loaders:\n","        raise ValueError(\"The argument 'name' must be one of 'mnist', 'cifar10', or 'celeba'.\")\n","\n","    return loaders[name.lower()]()\n","\n","def load_dataset(\n","    name: str, flatten: bool = False, binarize: bool = False\n",") -> Tuple[np.ndarray, np.ndarray]:\n","    \"\"\"Load and preprocess dataset.\"\"\"\n","    train_data, test_data = _load_dataset(name)\n","\n","    # Ensure data is float32 for further processing\n","    train_data = train_data.astype(\"float32\")\n","    test_data = test_data.astype(\"float32\")\n","\n","    # Binarize the data (if enabled)\n","    if binarize:\n","        train_data = (train_data > 128).astype(\"float32\")\n","        test_data = (test_data > 128).astype(\"float32\")\n","    else:\n","        train_data /= 255.0\n","        test_data /= 255.0\n","\n","    # Adjust data format to (N, C, H, W) for channels-first format\n","    train_data = np.transpose(train_data, (0, 3, 1, 2))\n","    test_data = np.transpose(test_data, (0, 3, 1, 2))\n","\n","    # Flatten the data (if enabled)\n","    if flatten:\n","        train_data = train_data.reshape(train_data.shape[0], -1)\n","        test_data = test_data.reshape(test_data.shape[0], -1)\n","\n","    return train_data, test_data\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1734470279253,"user":{"displayName":"samar rabeh","userId":"13396335607551022904"},"user_tz":-60},"id":"CETj1QmWKmiB"},"outputs":[],"source":["import torch\n","from torchvision.utils import make_grid, save_image\n","from PIL import Image\n","from tqdm import tqdm\n","\n","def inpaint_ncsn(path, sigmas, use_cuda, n_samples, n_steps, dataset, direction):\n","    \"\"\"Perform image inpainting using a Noise Conditional Score Network (NCSN).\"\"\"\n","\n","    # Step 1: Define the model configuration based on dataset\n","    dataset_configs = {\n","        \"mnist\": {\"n_channels\": 1, \"image_size\": 28, \"num_classes\": 10, \"ngf\": None},\n","        \"cifar10\": {\"n_channels\": 3, \"image_size\": 32, \"num_classes\": 10, \"ngf\": 128},\n","        \"celeba\": {\"n_channels\": 3, \"image_size\": 32, \"num_classes\": 10, \"ngf\": 128},\n","    }\n","\n","    if dataset not in dataset_configs:\n","        raise ValueError(\"Invalid dataset name. Choose from 'mnist', 'cifar10', or 'celeba'.\")\n","\n","    config = dataset_configs[dataset]\n","    refine_net = NoiseConditionalScoreNetwork(\n","        n_channels=config[\"n_channels\"],\n","        image_size=config[\"image_size\"],\n","        num_classes=config[\"num_classes\"],\n","        ngf=config[\"ngf\"] if config[\"ngf\"] else 64,  # Default ngf=64 for MNIST\n","    )\n","\n","    # Step 2: Load the pretrained model\n","    checkpoint = torch.load(path)\n","    if isinstance(checkpoint, tuple):  # Handle optimizer state if present\n","        refine_net.load_state_dict(checkpoint[0])\n","    else:\n","        refine_net.load_state_dict(checkpoint)\n","\n","    if use_cuda:\n","        refine_net.cuda()\n","    refine_net.eval()\n","\n","    # Step 3: Load test data\n","    train_data, test_data = load_dataset(dataset, flatten=False, binarize=False)\n","\n","    data_loader = torch.utils.data.DataLoader(\n","        test_data, batch_size=n_samples, shuffle=False, num_workers=0, drop_last=True\n","    )\n","    test_samples = next(iter(data_loader))\n","\n","    # Step 4: Initialize random samples for inpainting\n","    noise_samples = torch.randn(\n","        n_samples,\n","        refine_net.n_channels,\n","        refine_net.image_size,\n","        refine_net.image_size,\n","        device=\"cuda\" if use_cuda else \"cpu\",\n","    )\n","\n","    # Save original test samples\n","    save_image(\n","        test_samples,\n","        f\"original_{dataset}_{direction}_{n_steps}_{n_samples}.png\",\n","        nrow=5,\n","    )\n","\n","    # Step 5: Perform annealed Langevin dynamics inpainting\n","    generated_images, occluded_image = anneal_Langevin_dynamics_inpainting(\n","        noise_samples,\n","        test_samples,\n","        refine_net,\n","        sigmas,\n","        n_steps_each=n_steps,\n","        step_lr=0.00002,\n","        img_size=refine_net.image_size,\n","        n_channels=refine_net.n_channels,\n","        direction=direction,\n","    )\n","\n","    # Step 6: Create image grids\n","    occluded_grid = make_grid(occluded_image, nrow=1, normalize=True, scale_each=True)\n","    test_grid = make_grid(test_samples, nrow=1, normalize=True, scale_each=True)\n","\n","    images_to_save = []\n","    for i, generated_sample in tqdm(enumerate(generated_images), desc=\"Saving grids\"):\n","        # Reshape sample for grid creation\n","        generated_sample = generated_sample.view(\n","            n_samples,\n","            refine_net.n_channels,\n","            refine_net.image_size,\n","            refine_net.image_size,\n","        )\n","\n","        # Combine occluded, generated, and test grids\n","        generated_grid = make_grid(\n","            generated_sample, nrow=n_samples, normalize=True, scale_each=True\n","        )\n","        combined_grid = torch.cat([occluded_grid, generated_grid, test_grid], dim=2)\n","\n","        # Save every 10th iteration as an image\n","        if i % 10 == 0:\n","            img = Image.fromarray(\n","                combined_grid.mul(255)\n","                .add(0.5)\n","                .clamp(0, 255)\n","                .permute(1, 2, 0)\n","                .to(\"cpu\", torch.uint8)\n","                .numpy()\n","            )\n","            images_to_save.append(img)\n","\n","    return images_to_save\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"elapsed":860,"status":"error","timestamp":1734470280099,"user":{"displayName":"samar rabeh","userId":"13396335607551022904"},"user_tz":-60},"id":"U922O6d4KmiB","outputId":"2774081f-6f80-4616-c3c3-db23bd767bf1"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-aec18b24961f>:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  checkpoint = torch.load(path)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-d7d810c2e88c>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mimgs_per_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdirection\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mimages_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minpaint_ncsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mimgs_per_direction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_to_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-aec18b24961f>\u001b[0m in \u001b[0;36minpaint_ncsn\u001b[0;34m(path, sigmas, use_cuda, n_samples, n_steps, dataset, direction)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Step 2: Load the pretrained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Handle optimizer state if present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mrefine_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m         return _legacy_load(\n\u001b[0m\u001b[1;32m   1385\u001b[0m             \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1636\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1564\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m                 \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m                 \u001b[0;31m# stop wrapping with TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \"\"\"\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mbackend_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_privateuse1_backend_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mdevice_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_available\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdevice_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0;34mf\"Attempting to deserialize object on a {backend_name.upper()} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;34mf\"device but torch.{backend_name}.is_available() is False. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."]}],"source":["# def inpaint_ncsn(path, sigmas, use_cuda, n_samples, n_steps, dataset, direction):\n","path = \"/content/drive/My Drive/work/notebooks/pretrained_models/cifar10.pth\"\n","lambda_min = 0.01\n","lambda_max = 1\n","n_lambdas = 10\n","sigmas = torch.tensor(\n","        np.exp(\n","            np.linspace(\n","                np.log(lambda_max), np.log(lambda_min), n_lambdas\n","            )\n","        ),\n","        dtype=torch.float32,\n","    )\n","n_samples = 10\n","n_steps = 100\n","dataset = \"cifar10\" #\"celebra\" # \"cifar10\" # \"mnist\"\n","directions = [\"left\", \"right\", \"top\", \"bottom\"]\n","imgs_per_direction = []\n","for direction in directions:\n","    images_to_save = inpaint_ncsn(path, sigmas, True, n_samples, n_steps, dataset, direction)\n","    imgs_per_direction.append(images_to_save)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WsGxW747RfZf","executionInfo":{"status":"aborted","timestamp":1734470280293,"user_tz":-60,"elapsed":207,"user":{"displayName":"samar rabeh","userId":"13396335607551022904"}}},"outputs":[],"source":["\n","for i in range(len(directions)):\n","    images_to_save = imgs_per_direction[i]\n","\n","\n","    plt.imshow(imgs_per_direction[i][-1])\n","    plt.axis('off')\n","    # Enregistrer et afficher\n","    filename = '/content/drive/My Drive/work/notebooks/pretrained_models/output_image_{}_{}.png'.format(i, directions[i])\n","    #print(f\"Saving image to: {filename}\")\n","    plt.savefig(filename, bbox_inches='tight')\n","    plt.show()\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}